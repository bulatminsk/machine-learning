# Linear regresion

[Linear regresion](https://en.wikipedia.org/wiki/Linear_regression) is the most basic type of regression and is about to trace a line that predics the most probale spot of a new point.

![image](https://github.com/javiabellan/machine-learning/blob/master/reference/models/regression/linear-regression/linearRegression.png)


## One step apprach

Look at [this video](https://www.youtube.com/watch?v=SvmueyhSkgQ&index=8&list=PLQVvvaa0QuDfKTOs3Keq_kaG2P55YRn5v)


## Gradient descent apprach

Another way to obtain the line is using gradient descent:

 1. First, we declare iniaal values for the variables we want to optimize: 'm' and 'n'.
 2. Then, we define an error function to describe how well our regression performs.
 3. The

![image](https://github.com/javiabellan/machine-learning/blob/master/reference/models/regression/linear-regression/linearReg-gradDesc.png)

![image](https://github.com/mattnedrich/GradientDescentExample/blob/master/gradient_descent_example.gif)

#### More info
 * [Siraj inntroductory video](https://youtu.be/UIFMLK2nj_w?t=2m)
 * [Detailed explanation](https://spin.atomicobject.com/2014/06/24/gradient-descent-linear-regression/)
 * [A github repo](https://github.com/alberduris/The_Math_of_Intelligence/tree/master/Week1)

## One step VS Gradient descent

 * [link 1](https://stackoverflow.com/questions/18191890/why-gradient-descent-when-we-can-solve-linear-regression-analytically)
 * [link 2](https://stats.stackexchange.com/questions/278755/why-use-gradient-descent-for-linear-regression-when-a-closed-form-math-solution)


## TODO

[repasar este repo](https://github.com/alberduris/The_Math_of_Intelligence/tree/master/Week1)
